{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "No duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at column distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    \"Marital status\",\n",
    "    \"Application mode\",\n",
    "    \"Application order\",\n",
    "    \"Course\",\n",
    "    \"Daytime/evening attendance\",\n",
    "    \"Previous qualification\",\n",
    "    \"Nacionality\",\n",
    "    \"Mother's qualification\",\n",
    "    \"Father's qualification\",\n",
    "    \"Mother's occupation\",\n",
    "    \"Father's occupation\",\n",
    "    \"Displaced\",\n",
    "    \"Educational special needs\",\n",
    "    \"Debtor\",\n",
    "    \"Tuition fees up to date\",\n",
    "    \"Gender\",\n",
    "    \"Scholarship holder\",\n",
    "    \"International\",\n",
    "    \"Curricular units 1st sem (credited)\",\n",
    "    \"Curricular units 1st sem (enrolled)\",\n",
    "    \"Curricular units 1st sem (evaluations)\",\n",
    "    \"Curricular units 1st sem (approved)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\n",
    "    \"Curricular units 2nd sem (credited)\",\n",
    "    \"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\",\n",
    "    \"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\n",
    "]\n",
    "\n",
    "numerical_columns = [\n",
    "    \"Previous qualification (grade)\",\n",
    "    \"Admission grade\",\n",
    "    \"Age at enrollment\",\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 2nd sem (grade)\",\n",
    "    \"Unemployment rate\",\n",
    "    \"Inflation rate\",\n",
    "    \"GDP\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at distributions for numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_columns:\n",
    "    print(column)\n",
    "    # # Calculate the IQR (Interquartile Range)\n",
    "    # Q1 = train_df[column].quantile(0.25)\n",
    "    # Q3 = train_df[column].quantile(0.75)\n",
    "    # IQR = Q3 - Q1\n",
    "\n",
    "    # # Calculate the bin width using Freedman-Diaconis rule\n",
    "    # bin_width = 2 * IQR * (len(train_df[column]) ** (-1/3))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    sns.kdeplot(ax=axes[0], x=train_df[column], fill=True)\n",
    "    # sns.histplot(ax=axes[0], x=train_df[column], binwidth=bin_width, kde=True)\n",
    "    axes[0].set_title(column)\n",
    "\n",
    "    # sns.histplot(ax=axes[1], x=train_df[column], hue=train_df[\"Target\"], binwidth=bin_width, kde=True)\n",
    "    sns.kdeplot(ax=axes[1], x=train_df[column], hue=train_df[\"Target\"], fill=True)\n",
    "    axes[1].set_title(f\"{column} per Target\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at distribution of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns:\n",
    "    print(column)\n",
    "\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    ratios = train_df[column].value_counts(normalize=True)\n",
    "    sns.barplot(ax=axes[0], x=ratios.index, y=ratios.to_list())\n",
    "    axes[0].set_title(column)\n",
    "    axes[0].tick_params(axis=\"x\", labelrotation=90)\n",
    "    axes[0].set_ylim(0, 1)\n",
    "\n",
    "    grouped_counts = train_df.groupby(\"Target\")[column].value_counts(normalize=True)\n",
    "    flattened_df = grouped_counts.reset_index()\n",
    "    flattened_df.columns = [\"Target\", column, \"Proportion\"]\n",
    "    sns.barplot(\n",
    "        x=flattened_df[column], y=flattened_df[\"Proportion\"], hue=flattened_df[\"Target\"]\n",
    "    )\n",
    "    axes[1].set_title(f\"{column} per Target\")\n",
    "    axes[1].tick_params(axis=\"x\", labelrotation=90)\n",
    "    axes[1].set_ylim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unneeded columns, like id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"id\"]\n",
    "train_df.drop(columns=columns_to_drop, inplace=True)\n",
    "test_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_proportions = train_df[\"Target\"].value_counts(normalize=True)\n",
    "normalized_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "over = SMOTE(sampling_strategy=\"auto\", random_state=random_state)\n",
    "model = RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "pipeline = ImbPipeline(steps=[(\"over\", over), (\"model\", model)])\n",
    "\n",
    "X = train_df.drop(columns=\"Target\")\n",
    "y = train_df[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'model__criterion': 'entropy', 'model__max_depth': 3, 'model__n_estimators': 5}\n",
      "Best accuracy:  0.7822231356713637\n",
      "Test accuracy:  0.78659174072138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "param_grid = {\"model__n_estimators\" : [5],\n",
    "              \"model__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"model__max_depth\" : [3]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator= pipeline,\n",
    "                       param_grid = param_grid,\n",
    "                       scoring= \"accuracy\",\n",
    "                       cv=5)\n",
    "\n",
    "\n",
    "X = train_df.drop(columns=\"Target\")\n",
    "y = train_df[\"Target\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best accuracy: \", grid_search.best_score_)\n",
    "\n",
    "\n",
    "# X_test = test_df.drop(columns=\"Target\")\n",
    "# y_test = test_df[\"Target\"]\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_val, y_val)\n",
    "print(\"Test accuracy: \", test_accuracy)\n",
    "\n",
    "test_predictions = best_model.predict(test_df)\n",
    "\n",
    "prediction_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"Target\": test_predictions\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "prediction_df.to_csv(\"test_predictions.csv\", index=False)\n",
    "\n",
    "# # Print the test accuracy\n",
    "# test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "# print(\"Test accuracy: \", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
